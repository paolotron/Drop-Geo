{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ml.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPUt/tSgz2k6rg37X8t/E3u"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEOICy7sAhkV"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/paolotron/Drop-Geo.git\n",
        "!gdown --id 1QpF5nO1SivJ5QOx1kkhoCeMqFvvrksey\n",
        "!unzip pitts30k.zip -d Drop-Geo/dataset\n",
        "!pip install -r /content/Drop-Geo/requirements.txt\n",
        "!rm pitts30k.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python Drop-Geo/source/train.py --datasets_folder Drop-Geo/dataset/ --device cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfNOTXlsB4DI",
        "outputId": "8fcd0de7-44f9-4b17-a0dc-f9fdc8a2c96e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-01-03 14:30:39   Arguments: Namespace(cache_refresh_rate=1000, datasets_folder='Drop-Geo/dataset/', device='cuda', epochs_num=50, exp_name='default', gem_power=None, infer_batch_size=16, lr=1e-05, margin=0.1, neg_samples_num=1000, negs_num_per_query=10, netvlad_clusters=None, num_workers=8, output_folder='runs/default/2022-01-03_14-30-39', patience=3, queries_per_epoch=5000, recall_values=[1, 5, 10, 20], seed=0, train_batch_size=4, train_positives_dist_threshold=10, val_positive_dist_threshold=25)\n",
            "2022-01-03 14:30:39   The outputs are being saved in runs/default/2022-01-03_14-30-39\n",
            "2022-01-03 14:30:39   Using 1 GPUs and 2 CPUs\n",
            "2022-01-03 14:30:39   Loading dataset Pitts30k from folder Drop-Geo/dataset/\n",
            "2022-01-03 14:30:40   There are 96 queries without any positives within the training set. They won't be considered as they're useless for training.\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "2022-01-03 14:30:40   Train query set: < TripletsDataset, pitts30k - #database: 10000; #queries: 7320 >\n",
            "2022-01-03 14:30:40   Val set: < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >\n",
            "2022-01-03 14:30:40   Test set: < BaseDataset, pitts30k - #database: 10000; #queries: 6816 >\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100% 44.7M/44.7M [00:00<00:00, 86.5MB/s]\n",
            "2022-01-03 14:30:41   Train only conv4 of the ResNet-18 (remove conv5), freeze the previous ones\n",
            "2022-01-03 14:30:51   Output dimension of the model is 256\n",
            "2022-01-03 14:30:51   Start training epoch: 00\n",
            "2022-01-03 14:30:51   Cache: 0 / 5\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:57<00:00,  3.89it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 798.88it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [05:10<00:00,  1.24s/it]\n",
            "2022-01-03 14:38:59   Epoch[00](0/5): current batch triplet loss = 0.0691, average epoch triplet loss = 0.0794\n",
            "2022-01-03 14:38:59   Cache: 1 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:56<00:00,  3.89it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 781.80it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [05:05<00:00,  1.22s/it]\n",
            "2022-01-03 14:47:02   Epoch[00](1/5): current batch triplet loss = 0.0927, average epoch triplet loss = 0.0766\n",
            "2022-01-03 14:47:02   Cache: 2 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:56<00:00,  3.89it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 823.08it/s]\n",
            "100%|█████████████████████████████████████████████████████████████| 250/250 [05:06<00:00,  1.23s/it]\n",
            "2022-01-03 14:55:07   Epoch[00](2/5): current batch triplet loss = 0.0746, average epoch triplet loss = 0.0743\n",
            "2022-01-03 14:55:07   Cache: 3 / 5\n",
            "100%|█████████████████████████████████████████████████████████████| 688/688 [02:57<00:00,  3.88it/s]\n",
            "100%|██████████████████████████████████████████████████████████| 1000/1000 [00:01<00:00, 800.98it/s]\n",
            " 32%|████████████████████                                          | 81/250 [01:46<03:19,  1.18s/it]"
          ]
        }
      ]
    }
  ]
}