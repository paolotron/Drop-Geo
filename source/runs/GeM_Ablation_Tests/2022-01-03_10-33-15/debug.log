2022-01-03 10:33:15   Arguments: Namespace(train_batch_size=2, infer_batch_size=16, margin=0.1, epochs_num=20, patience=3, lr=0.0001, cache_refresh_rate=1000, queries_per_epoch=3000, negs_num_per_query=10, neg_samples_num=1000, seed=0, device='cuda', num_workers=4, val_positive_dist_threshold=25, train_positives_dist_threshold=10, recall_values=[1, 5, 10, 20], datasets_folder='../data/', exp_name='default', netvlad_clusters=None, gem_power=3.0, output_folder='runs\\default\\2022-01-03_10-33-15')
2022-01-03 10:33:15   The outputs are being saved in runs\default\2022-01-03_10-33-15
2022-01-03 10:33:15   Using 1 GPUs and 4 CPUs
2022-01-03 10:33:15   Loading dataset Pitts30k from folder ../data/
2022-01-03 10:33:15   There are 96 queries without any positives within the training set. They won't be considered as they're useless for training.
2022-01-03 10:33:15   Train query set: < TripletsDataset, pitts30k - #database: 10000; #queries: 7320 >
2022-01-03 10:33:17   Val set: < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >
2022-01-03 10:33:18   Test set: < BaseDataset, pitts30k - #database: 10000; #queries: 6816 >
2022-01-03 10:33:18   Train only conv4 of the ResNet-18 (remove conv5), freeze the previous ones
2022-01-03 10:33:18   Output dimension of the model is 256
2022-01-03 10:33:18   Start training epoch: 00
2022-01-03 10:33:18   Cache: 0 / 3
2022-01-03 10:37:58   Epoch[00](0/3): current batch triplet loss = 0.0327, average epoch triplet loss = 0.0529
2022-01-03 10:37:58   Cache: 1 / 3
2022-01-03 10:42:29   Epoch[00](1/3): current batch triplet loss = 0.0384, average epoch triplet loss = 0.0497
2022-01-03 10:42:29   Cache: 2 / 3
2022-01-03 10:46:58   Epoch[00](2/3): current batch triplet loss = 0.0163, average epoch triplet loss = 0.0455
2022-01-03 10:46:58   Finished epoch 00 in 0:13:39, average epoch triplet loss = 0.0455
2022-01-03 10:46:58   Extracting database features for evaluation/testing
2022-01-03 10:48:39   Extracting queries features for evaluation/testing
2022-01-03 10:49:56   Calculating recalls
2022-01-03 10:50:19   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 54.6, R@5: 77.1, R@10: 84.9, R@20: 90.5
2022-01-03 10:50:19   Improved: previous best R@5 = 0.0, current R@5 = 77.1
2022-01-03 10:50:19   Start training epoch: 01
2022-01-03 10:50:19   Cache: 0 / 3
2022-01-03 10:54:49   Epoch[01](0/3): current batch triplet loss = 0.0473, average epoch triplet loss = 0.0326
2022-01-03 10:54:49   Cache: 1 / 3
2022-01-03 10:59:20   Epoch[01](1/3): current batch triplet loss = 0.0122, average epoch triplet loss = 0.0316
2022-01-03 10:59:20   Cache: 2 / 3
2022-01-03 11:03:52   Epoch[01](2/3): current batch triplet loss = 0.0308, average epoch triplet loss = 0.0300
2022-01-03 11:03:52   Finished epoch 01 in 0:13:33, average epoch triplet loss = 0.0300
2022-01-03 11:03:52   Extracting database features for evaluation/testing
2022-01-03 11:05:45   Extracting queries features for evaluation/testing
2022-01-03 11:07:13   Calculating recalls
2022-01-03 11:07:36   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 53.1, R@5: 75.3, R@10: 82.4, R@20: 88.9
2022-01-03 11:07:36   Not improved: 1 / 3: best R@5 = 77.1, current R@5 = 75.3
2022-01-03 11:07:36   Start training epoch: 02
2022-01-03 11:07:36   Cache: 0 / 3
2022-01-03 11:12:22   Epoch[02](0/3): current batch triplet loss = 0.0399, average epoch triplet loss = 0.0270
2022-01-03 11:12:22   Cache: 1 / 3
2022-01-03 11:17:02   Epoch[02](1/3): current batch triplet loss = 0.0348, average epoch triplet loss = 0.0257
2022-01-03 11:17:02   Cache: 2 / 3
2022-01-03 11:21:41   Epoch[02](2/3): current batch triplet loss = 0.0122, average epoch triplet loss = 0.0254
2022-01-03 11:21:41   Finished epoch 02 in 0:14:04, average epoch triplet loss = 0.0254
2022-01-03 11:21:41   Extracting database features for evaluation/testing
2022-01-03 11:23:28   Extracting queries features for evaluation/testing
2022-01-03 11:25:05   Calculating recalls
2022-01-03 11:25:32   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 58.9, R@5: 80.4, R@10: 87.2, R@20: 92.0
2022-01-03 11:25:32   Improved: previous best R@5 = 77.1, current R@5 = 80.4
2022-01-03 11:25:32   Start training epoch: 03
2022-01-03 11:25:32   Cache: 0 / 3
2022-01-03 11:30:32   Epoch[03](0/3): current batch triplet loss = 0.0305, average epoch triplet loss = 0.0232
2022-01-03 11:30:32   Cache: 1 / 3
2022-01-03 11:35:11   Epoch[03](1/3): current batch triplet loss = 0.0443, average epoch triplet loss = 0.0223
2022-01-03 11:35:11   Cache: 2 / 3
2022-01-03 11:39:51   Epoch[03](2/3): current batch triplet loss = 0.0224, average epoch triplet loss = 0.0216
2022-01-03 11:39:51   Finished epoch 03 in 0:14:18, average epoch triplet loss = 0.0216
2022-01-03 11:39:51   Extracting database features for evaluation/testing
2022-01-03 11:41:44   Extracting queries features for evaluation/testing
2022-01-03 11:43:09   Calculating recalls
2022-01-03 11:43:34   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 56.5, R@5: 78.0, R@10: 85.4, R@20: 90.6
2022-01-03 11:43:34   Not improved: 1 / 3: best R@5 = 80.4, current R@5 = 78.0
2022-01-03 11:43:34   Start training epoch: 04
2022-01-03 11:43:34   Cache: 0 / 3
2022-01-03 11:48:09   Epoch[04](0/3): current batch triplet loss = 0.0056, average epoch triplet loss = 0.0196
2022-01-03 11:48:09   Cache: 1 / 3
2022-01-03 11:52:58   Epoch[04](1/3): current batch triplet loss = 0.0423, average epoch triplet loss = 0.0185
2022-01-03 11:52:58   Cache: 2 / 3
2022-01-03 11:57:34   Epoch[04](2/3): current batch triplet loss = 0.0094, average epoch triplet loss = 0.0182
2022-01-03 11:57:34   Finished epoch 04 in 0:13:59, average epoch triplet loss = 0.0182
2022-01-03 11:57:34   Extracting database features for evaluation/testing
2022-01-03 11:59:16   Extracting queries features for evaluation/testing
2022-01-03 12:00:34   Calculating recalls
2022-01-03 12:00:57   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 55.2, R@5: 77.4, R@10: 84.7, R@20: 90.8
2022-01-03 12:00:57   Not improved: 2 / 3: best R@5 = 80.4, current R@5 = 77.4
2022-01-03 12:00:57   Start training epoch: 05
2022-01-03 12:00:57   Cache: 0 / 3
2022-01-03 12:05:26   Epoch[05](0/3): current batch triplet loss = 0.0000, average epoch triplet loss = 0.0164
2022-01-03 12:05:26   Cache: 1 / 3
2022-01-03 12:09:58   Epoch[05](1/3): current batch triplet loss = 0.0127, average epoch triplet loss = 0.0171
2022-01-03 12:09:58   Cache: 2 / 3
2022-01-03 12:14:33   Epoch[05](2/3): current batch triplet loss = 0.0017, average epoch triplet loss = 0.0168
2022-01-03 12:14:33   Finished epoch 05 in 0:13:35, average epoch triplet loss = 0.0168
2022-01-03 12:14:33   Extracting database features for evaluation/testing
2022-01-03 12:16:26   Extracting queries features for evaluation/testing
2022-01-03 12:17:58   Calculating recalls
2022-01-03 12:18:24   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 55.8, R@5: 77.1, R@10: 84.7, R@20: 90.3
2022-01-03 12:18:24   Not improved: 3 / 3: best R@5 = 80.4, current R@5 = 77.1
2022-01-03 12:18:24   Performance did not improve for 3 epochs. Stop training.
2022-01-03 12:18:24   Best R@5: 80.4
2022-01-03 12:18:24   Trained for 06 epochs, in total in 1:45:08
2022-01-03 12:18:24   Extracting database features for evaluation/testing
2022-01-03 12:20:15   Extracting queries features for evaluation/testing
2022-01-03 12:21:56   
Traceback (most recent call last):
  File "C:\Users\ferre\Desktop\Poli\Machine learning and pattern recognition\Drop-Geo\source\train.py", line 147, in <module>
    recalls, recalls_str = test.test(args, test_ds, model)
  File "C:\Users\ferre\Desktop\Poli\Machine learning and pattern recognition\Drop-Geo\source\test.py", line 31, in test
    for inputs, indices in tqdm(queries_dataloader, ncols=100):
  File "C:\Users\ferre\anaconda3\lib\site-packages\tqdm\std.py", line 1180, in __iter__
    for obj in iterable:
  File "C:\Users\ferre\anaconda3\lib\site-packages\torch\utils\data\dataloader.py", line 521, in __next__
    data = self._next_data()
  File "C:\Users\ferre\anaconda3\lib\site-packages\torch\utils\data\dataloader.py", line 1203, in _next_data
    return self._process_data(data)
  File "C:\Users\ferre\anaconda3\lib\site-packages\torch\utils\data\dataloader.py", line 1229, in _process_data
    data.reraise()
  File "C:\Users\ferre\anaconda3\lib\site-packages\torch\_utils.py", line 434, in reraise
    raise exception
RuntimeError: Caught RuntimeError in DataLoader worker process 3.
Original Traceback (most recent call last):
  File "C:\Users\ferre\anaconda3\lib\site-packages\torch\utils\data\_utils\worker.py", line 287, in _worker_loop
    data = fetcher.fetch(index)
  File "C:\Users\ferre\anaconda3\lib\site-packages\torch\utils\data\_utils\fetch.py", line 52, in fetch
    return self.collate_fn(data)
  File "C:\Users\ferre\anaconda3\lib\site-packages\torch\utils\data\_utils\collate.py", line 84, in default_collate
    return [default_collate(samples) for samples in transposed]
  File "C:\Users\ferre\anaconda3\lib\site-packages\torch\utils\data\_utils\collate.py", line 84, in <listcomp>
    return [default_collate(samples) for samples in transposed]
  File "C:\Users\ferre\anaconda3\lib\site-packages\torch\utils\data\_utils\collate.py", line 54, in default_collate
    storage = elem.storage()._new_shared(numel)
  File "C:\Users\ferre\anaconda3\lib\site-packages\torch\storage.py", line 155, in _new_shared
    return cls._new_using_filename(size)
RuntimeError: falseINTERNAL ASSERT FAILED at "..\\aten\\src\\ATen\\MapAllocator.cpp":135, please report a bug to PyTorch. Couldn't open shared file mapping: <0000022DA9B3F0A2>, error code: <1455>


